{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Covid-19 Chest X-Ray Prediction","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport glob\nimport torch\nimport shutil\nimport itertools\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np \nimport pandas as pd \n\nfrom pathlib import Path\nfrom torch.nn import functional as F\nfrom torchvision import datasets, models, transforms\nimport time\nimport copy\nimport tqdm\nfrom random import shuffle","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-06T12:52:11.113629Z","iopub.execute_input":"2022-05-06T12:52:11.113887Z","iopub.status.idle":"2022-05-06T12:52:12.615350Z","shell.execute_reply.started":"2022-05-06T12:52:11.113861Z","shell.execute_reply":"2022-05-06T12:52:12.614467Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Data Visualisation","metadata":{}},{"cell_type":"code","source":"# пути к данным\ncovid_path = '../input/covid19-radiography-database/COVID-19_Radiography_Dataset/COVID/images'\nnormal_path = '../input/covid19-radiography-database/COVID-19_Radiography_Dataset/Normal/images'","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2022-05-06T12:52:14.955498Z","iopub.execute_input":"2022-05-06T12:52:14.955832Z","iopub.status.idle":"2022-05-06T12:52:14.959877Z","shell.execute_reply.started":"2022-05-06T12:52:14.955801Z","shell.execute_reply":"2022-05-06T12:52:14.959053Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Sorting out the files\nРазделим данные на train и valid выборки в соотношении 80:20. К распределим соответсвующие изображения по папкам.","metadata":{}},{"cell_type":"code","source":"# создания соответсвующих разделов \nos.mkdir('/kaggle/working/train')\nos.mkdir('/kaggle/working/valid')\n\nos.mkdir('/kaggle/working/train/covid')\nos.mkdir('/kaggle/working/valid/covid')\n\nos.mkdir('/kaggle/working/train/normal')\nos.mkdir('/kaggle/working/valid/normal')\n","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:52:17.861745Z","iopub.execute_input":"2022-05-06T12:52:17.862171Z","iopub.status.idle":"2022-05-06T12:52:17.868913Z","shell.execute_reply.started":"2022-05-06T12:52:17.862132Z","shell.execute_reply":"2022-05-06T12:52:17.867912Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# разделение на выборки\ncovid_train_len = int(np.floor(len(os.listdir(covid_path))*0.8))\ncovid_len = len(os.listdir(covid_path))\n\nnormal_train_len = int(np.floor(len(os.listdir(normal_path))*0.8))\nnormal_len = len(os.listdir(normal_path))","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:52:18.281515Z","iopub.execute_input":"2022-05-06T12:52:18.281945Z","iopub.status.idle":"2022-05-06T12:52:18.713170Z","shell.execute_reply.started":"2022-05-06T12:52:18.281904Z","shell.execute_reply":"2022-05-06T12:52:18.712290Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Переносим изображения по соответсвующим папкам\nfor trainimg in itertools.islice(glob.iglob(os.path.join(covid_path, '*.png')), covid_train_len):\n    shutil.copy(trainimg, '/kaggle/working/train/covid')\n    \nfor trainimg in itertools.islice(glob.iglob(os.path.join(normal_path, '*.png')), normal_train_len):\n    shutil.copy(trainimg, '/kaggle/working/train/normal')\n\nfor testimg in itertools.islice(glob.iglob(os.path.join(covid_path, '*.png')), covid_train_len, covid_len):\n    shutil.copy(testimg, '/kaggle/working/valid/covid')\n\nfor testimg in itertools.islice(glob.iglob(os.path.join(normal_path, '*.png')), normal_train_len, normal_len):\n    shutil.copy(testimg, '/kaggle/working/valid/normal')","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:52:18.715278Z","iopub.execute_input":"2022-05-06T12:52:18.715764Z","iopub.status.idle":"2022-05-06T12:53:23.405076Z","shell.execute_reply.started":"2022-05-06T12:52:18.715727Z","shell.execute_reply":"2022-05-06T12:53:23.404276Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(16,5))\nfig.suptitle(\"COVID19 Positive\", size=22)\nimg_paths = os.listdir('/kaggle/working/train/covid')\nshuffle(img_paths)\n\nfor i,image in enumerate(img_paths[:4]):\n    img = cv2.imread(os.path.join('/kaggle/working/train/covid', image))\n    plt.subplot(1,4, i+1, frameon=False)\n    plt.imshow(img)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:53:23.406755Z","iopub.execute_input":"2022-05-06T12:53:23.407079Z","iopub.status.idle":"2022-05-06T12:53:23.934711Z","shell.execute_reply.started":"2022-05-06T12:53:23.407040Z","shell.execute_reply":"2022-05-06T12:53:23.933813Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Преобразуем данные","metadata":{}},{"cell_type":"code","source":"#правила преобразования для train и valid/test\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.ColorJitter(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    \n    'validation': transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n}","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:53:27.137255Z","iopub.execute_input":"2022-05-06T12:53:27.137572Z","iopub.status.idle":"2022-05-06T12:53:27.146417Z","shell.execute_reply.started":"2022-05-06T12:53:27.137544Z","shell.execute_reply":"2022-05-06T12:53:27.143675Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# преобразования изображений\ndata_images = {\n    'train': datasets.ImageFolder('/kaggle/working/train', data_transforms['train']),\n    'validation': datasets.ImageFolder('/kaggle/working/valid', data_transforms['validation'])\n}","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:53:27.769329Z","iopub.execute_input":"2022-05-06T12:53:27.769659Z","iopub.status.idle":"2022-05-06T12:53:27.830341Z","shell.execute_reply.started":"2022-05-06T12:53:27.769629Z","shell.execute_reply":"2022-05-06T12:53:27.829505Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#создание dataloaders для изображения\ndataloaders = {\n    'train': torch.utils.data.DataLoader(data_images['train'], batch_size=16, shuffle=True, num_workers=0),\n    'validation': torch.utils.data.DataLoader(data_images['validation'], batch_size=16,shuffle=True,num_workers=0)\n}","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:53:33.855166Z","iopub.execute_input":"2022-05-06T12:53:33.855506Z","iopub.status.idle":"2022-05-06T12:53:33.861281Z","shell.execute_reply.started":"2022-05-06T12:53:33.855475Z","shell.execute_reply":"2022-05-06T12:53:33.860204Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Creating model","metadata":{}},{"cell_type":"code","source":"# проверяем возможность учится на gpu\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:53:44.739246Z","iopub.execute_input":"2022-05-06T12:53:44.741284Z","iopub.status.idle":"2022-05-06T12:53:44.747268Z","shell.execute_reply.started":"2022-05-06T12:53:44.741241Z","shell.execute_reply":"2022-05-06T12:53:44.746509Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Training our model","metadata":{}},{"cell_type":"code","source":"# функция обучения модели\ndef trained_model(model, dataloaders, criterion, optimizer, epochs):\n    since = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_loss = np.inf\n    history=[]\n    # перебираем эпохи\n    for epoch in range(epochs):\n        \n        print('Epoch {}/{}'.format(epoch+1, epochs))\n        print('-' * 10)\n        phase_history=[]\n        # для фазы train и valid считаем loss и accuracy\n        for phase in ['train', 'validation']:\n            if phase == 'train':\n                model.train() #this trains the model\n            else:\n                model.eval() #this evaluates the model\n\n            running_loss, running_corrects = 0.0, 0 \n\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device) #отправляем преобразованные картинки на cpu/gpu\n                labels = labels.to(device) #отправляем labels на cpu/gpu\n                \n                optimizer.zero_grad()\n                \n                outputs = model(inputs) #учим\n                loss = criterion(outputs, labels) #считаем ошибка\n\n                if phase == 'train':\n                    optimizer.zero_grad() \n                    loss.backward() \n                    optimizer.step() \n\n                _, preds = torch.max(outputs, 1) \n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data) \n\n            epoch_loss = running_loss / len(data_images[phase]) \n            epoch_accuracy = running_corrects.double() / len(data_images[phase])\n            \n            print('{} Loss: {:.4f} | {} Accuracy: {:.4f}'.format(\n                    phase, epoch_loss, phase, epoch_accuracy))\n            if phase == 'validation' and epoch_loss < best_loss:\n                print('Val loss Decreased from {:.4f} to {:.4f} \\nSaving Weights... '.format(best_loss, epoch_loss))\n                best_loss = epoch_loss\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n            phase_history.append((epoch_loss, epoch_accuracy))\n        history.append(phase_history)\n        print()\n    \n    time_since = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_since // 60, time_since % 60))\n    print('Best val loss: {:.4f}'.format(best_loss))\n\n    model.load_state_dict(best_model_wts)\n    \n    return model, history","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:54:00.664987Z","iopub.execute_input":"2022-05-06T12:54:00.665383Z","iopub.status.idle":"2022-05-06T12:54:00.685373Z","shell.execute_reply.started":"2022-05-06T12:54:00.665349Z","shell.execute_reply":"2022-05-06T12:54:00.684280Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# ResNet18","metadata":{}},{"cell_type":"code","source":"model = models.resnet18(pretrained=True)\n# замораживаем параметры (веса)\nfor param in model.parameters():\n    param.requires_grad = False\n# num_features -- это размерность вектора фич, поступающего на вход FC-слою\n\nnum_features = model.fc.in_features\nn_classes = 2\n# Заменяем Fully-Connected слой на наш линейный классификатор\nmodel.fc = nn.Linear(num_features, n_classes)\nmodel = model.to(device)\n\n# Определяем оптимизатор, критерий\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.AdamW(model.fc.parameters())\n# optimizer = optim.SGD(model.fc.parameters(), lr=0.01, momentum=0.9)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#запускаем\nresult_model, history = trained_model(model=model, dataloaders=dataloaders, criterion=criterion, optimizer=optimizer, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:54:02.729010Z","iopub.execute_input":"2022-05-06T12:54:02.729395Z","iopub.status.idle":"2022-05-06T13:05:28.202090Z","shell.execute_reply.started":"2022-05-06T12:54:02.729360Z","shell.execute_reply":"2022-05-06T13:05:28.201103Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def plot_loss(history):\n    fig = plt.figure(figsize=(12,8))\n    train, test = zip(*history)\n    train_loss, train_acc = zip(*train)\n    val_loss, val_acc = zip(*test)\n    plt.plot(train_loss, label=\"train_loss\")\n    plt.plot(val_loss, label=\"val_loss\")\n    plt.legend(loc='best')\n    plt.xlabel(\"epochs\")\n    plt.ylabel(\"loss\")\n    plt.show()\n\ndef plot_accuracy(history):\n    fig = plt.figure(figsize=(12,8))\n    train, test = zip(*history)\n    train_loss, train_acc = zip(*train)\n    val_loss, val_acc = zip(*test)\n    plt.plot(train_acc, label=\"train_accuracy\")\n    plt.plot(val_acc, label=\"val_accuracy\")\n    plt.legend(loc='best')\n    plt.xlabel(\"epochs\")\n    plt.ylabel(\"loss\")\n    plt.show()\n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-06T14:05:50.937998Z","iopub.execute_input":"2022-05-06T14:05:50.938360Z","iopub.status.idle":"2022-05-06T14:05:50.948021Z","shell.execute_reply.started":"2022-05-06T14:05:50.938330Z","shell.execute_reply":"2022-05-06T14:05:50.946881Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"plot_loss(history)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T13:18:02.902784Z","iopub.execute_input":"2022-05-06T13:18:02.903148Z","iopub.status.idle":"2022-05-06T13:18:03.057797Z","shell.execute_reply.started":"2022-05-06T13:18:02.903114Z","shell.execute_reply":"2022-05-06T13:18:03.056990Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"#запускаем\nresult_model_adam, history = trained_model(model=model, dataloaders=dataloaders, criterion=criterion, optimizer=optimizer, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T13:42:59.795878Z","iopub.execute_input":"2022-05-06T13:42:59.796233Z","iopub.status.idle":"2022-05-06T13:54:23.714636Z","shell.execute_reply.started":"2022-05-06T13:42:59.796199Z","shell.execute_reply":"2022-05-06T13:54:23.713810Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"plot_loss(history)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T14:06:04.902864Z","iopub.execute_input":"2022-05-06T14:06:04.903233Z","iopub.status.idle":"2022-05-06T14:06:05.069744Z","shell.execute_reply.started":"2022-05-06T14:06:04.903201Z","shell.execute_reply":"2022-05-06T14:06:05.068854Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"plot_accuracy(history)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T14:06:10.789661Z","iopub.execute_input":"2022-05-06T14:06:10.789981Z","iopub.status.idle":"2022-05-06T14:06:10.939799Z","shell.execute_reply.started":"2022-05-06T14:06:10.789951Z","shell.execute_reply":"2022-05-06T14:06:10.938811Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"#dir for save model\nos.mkdir('/kaggle/working/models')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#save model\ntorch.save(result_model.state_dict(), 'models/weights.h5') #save the model's weights\n#load model\n# model.load_state_dict(torch.load('models/weights.h5')) #load the model's weights","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:00:22.586105Z","iopub.execute_input":"2022-05-06T11:00:22.586435Z","iopub.status.idle":"2022-05-06T11:00:22.800302Z","shell.execute_reply.started":"2022-05-06T11:00:22.586404Z","shell.execute_reply":"2022-05-06T11:00:22.79918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_model(model, num_images=6):\n    was_training = model.training\n    model.eval()\n    images_handeled = 0\n    ax = plt.figure()\n\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(dataloaders['validation']):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n    \n            for j in range(inputs.size()[0]):\n                images_handeled += 1    \n                ax = plt.subplot(num_images//2, 2, images_handeled)\n                ax.axis('off')\n                ax.set_title('Actual: {} predicted: {}'.format(class_names[labels[j].item()],class_names[preds[j]]))\n                imshow(inputs.cpu().data[j], (5,5))\n\n                if images_handeled == num_images:\n                    model.train(mode=was_training)\n                    return\n        model.train(mode=was_training)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T13:18:46.250030Z","iopub.execute_input":"2022-05-06T13:18:46.250419Z","iopub.status.idle":"2022-05-06T13:18:46.262147Z","shell.execute_reply.started":"2022-05-06T13:18:46.250378Z","shell.execute_reply":"2022-05-06T13:18:46.260949Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"class_names = ['covid', 'normal']\n#Statistics Based on ImageNet Data for Normalisation\nmean_nums = [0.485, 0.456, 0.406]\nstd_nums = [0.229, 0.224, 0.225]\ndef imshow(inp, size =(30,30), title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = mean_nums\n    std = std_nums\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.figure(figsize=size)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title, size=30)\n    plt.pause(0.001)  # pause a bit so that plots are updated","metadata":{"execution":{"iopub.status.busy":"2022-05-06T13:18:50.740848Z","iopub.execute_input":"2022-05-06T13:18:50.741190Z","iopub.status.idle":"2022-05-06T13:18:50.749713Z","shell.execute_reply.started":"2022-05-06T13:18:50.741156Z","shell.execute_reply":"2022-05-06T13:18:50.748860Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"visualize_model(result_model)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T13:18:57.407070Z","iopub.execute_input":"2022-05-06T13:18:57.407417Z","iopub.status.idle":"2022-05-06T13:18:58.970485Z","shell.execute_reply.started":"2022-05-06T13:18:57.407380Z","shell.execute_reply":"2022-05-06T13:18:58.969774Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"# Make prediction\n\n Я сделал на valid выборке, можно потестить на другом датасете","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report","metadata":{"execution":{"iopub.status.busy":"2022-05-06T13:19:30.249727Z","iopub.execute_input":"2022-05-06T13:19:30.250051Z","iopub.status.idle":"2022-05-06T13:19:30.256127Z","shell.execute_reply.started":"2022-05-06T13:19:30.250020Z","shell.execute_reply":"2022-05-06T13:19:30.255266Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"def predict(model,dataloader):\n    y_pred_list = []\n    y_true_list = []\n    with torch.no_grad():\n        for x_batch, y_batch in tqdm.tqdm(dataloader, leave=False):\n            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n            y_test_pred = model(x_batch)\n            y_test_pred = torch.log_softmax(y_test_pred, dim=1)\n            _, y_pred_tag = torch.max(y_test_pred, dim = 1)\n            y_pred_list.append(y_pred_tag.cpu().numpy())\n            y_true_list.append(y_batch.cpu().numpy())\n    y_pred_list = [i[0] for i in y_pred_list]\n    y_true_list = [i[0] for i in y_true_list]\n    return y_pred_list, y_true_list","metadata":{"execution":{"iopub.status.busy":"2022-05-06T13:26:46.090221Z","iopub.execute_input":"2022-05-06T13:26:46.090553Z","iopub.status.idle":"2022-05-06T13:26:46.099239Z","shell.execute_reply.started":"2022-05-06T13:26:46.090524Z","shell.execute_reply":"2022-05-06T13:26:46.098158Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"y_pred_list, y_true_list = predict(result_model_adam, dataloaders['validation'])","metadata":{"execution":{"iopub.status.busy":"2022-05-06T13:57:45.344763Z","iopub.execute_input":"2022-05-06T13:57:45.345093Z","iopub.status.idle":"2022-05-06T13:57:58.620906Z","shell.execute_reply.started":"2022-05-06T13:57:45.345051Z","shell.execute_reply":"2022-05-06T13:57:58.620214Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_true_list, y_pred_list))","metadata":{"execution":{"iopub.status.busy":"2022-05-06T13:58:05.637489Z","iopub.execute_input":"2022-05-06T13:58:05.637813Z","iopub.status.idle":"2022-05-06T13:58:05.649291Z","shell.execute_reply.started":"2022-05-06T13:58:05.637782Z","shell.execute_reply":"2022-05-06T13:58:05.648338Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Альтернативная модель","metadata":{}},{"cell_type":"code","source":"model = models.densenet121(pretrained=True)\n# замораживаем параметры (веса)\nfor param in model.parameters():\n    param.requires_grad = False\n# num_features -- это размерность вектора фич, поступающего на вход FC-слою\n\n# num_features = model.fc.in_features\nn_classes = 2\n# Заменяем Fully-Connected слой на наш линейный классификатор\nmodel.classifier = nn.Linear(1024, n_classes)\nmodel = model.to(device)\n\n# Определяем оптимизатор, критерий\ncriterion = nn.CrossEntropyLoss()\n# optimizer = optim.AdamW(model.classifier.parameters())\noptimizer = optim.SGD(model.classifier.parameters(),lr=0.1)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T13:28:07.806851Z","iopub.execute_input":"2022-05-06T13:28:07.807217Z","iopub.status.idle":"2022-05-06T13:28:08.083752Z","shell.execute_reply.started":"2022-05-06T13:28:07.807183Z","shell.execute_reply":"2022-05-06T13:28:08.082863Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"#запускаем\nresult_model_2, history_2 = trained_model(model=model, dataloaders=dataloaders, criterion=criterion, optimizer=optimizer, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T13:28:10.422504Z","iopub.execute_input":"2022-05-06T13:28:10.422838Z","iopub.status.idle":"2022-05-06T13:42:59.481725Z","shell.execute_reply.started":"2022-05-06T13:28:10.422806Z","shell.execute_reply":"2022-05-06T13:42:59.480784Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"plot_loss(history_2)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T13:58:22.284923Z","iopub.execute_input":"2022-05-06T13:58:22.285359Z","iopub.status.idle":"2022-05-06T13:58:22.439358Z","shell.execute_reply.started":"2022-05-06T13:58:22.285323Z","shell.execute_reply":"2022-05-06T13:58:22.438098Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"y_pred_list, y_true_list = predict(result_model_2, dataloaders['validation'])","metadata":{"execution":{"iopub.status.busy":"2022-05-06T13:58:48.974610Z","iopub.execute_input":"2022-05-06T13:58:48.974930Z","iopub.status.idle":"2022-05-06T13:59:06.587246Z","shell.execute_reply.started":"2022-05-06T13:58:48.974901Z","shell.execute_reply":"2022-05-06T13:59:06.586368Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_true_list, y_pred_list))","metadata":{"execution":{"iopub.status.busy":"2022-05-06T13:59:06.590293Z","iopub.execute_input":"2022-05-06T13:59:06.590805Z","iopub.status.idle":"2022-05-06T13:59:06.601339Z","shell.execute_reply.started":"2022-05-06T13:59:06.590764Z","shell.execute_reply":"2022-05-06T13:59:06.600347Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}