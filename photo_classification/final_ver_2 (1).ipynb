{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Covid-19 Chest X-Ray Prediction","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport torch\nimport glob\nimport shutil\nimport itertools\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport pickle\nimport torch.optim as optim\nimport numpy as np \nimport pandas as pd \nfrom sklearn.preprocessing import LabelEncoder\nfrom multiprocessing.pool import ThreadPool\n\nfrom tqdm import tqdm, tqdm_notebook\nfrom PIL import Image\nfrom pathlib import Path\nfrom torch.nn import functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import datasets, models, transforms\nimport time\nimport copy\nfrom random import shuffle\nimport pickle\nimport numpy as np\nfrom sklearn.metrics import classification_report\nfrom skimage import io\n\nimport matplotlib.patches as patches\nfrom matplotlib.font_manager import FontProperties","metadata":{"execution":{"iopub.status.busy":"2022-05-07T10:54:43.911205Z","iopub.execute_input":"2022-05-07T10:54:43.911513Z","iopub.status.idle":"2022-05-07T10:54:46.284801Z","shell.execute_reply.started":"2022-05-07T10:54:43.911478Z","shell.execute_reply":"2022-05-07T10:54:46.283984Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Data Visualisation\n\nDataset link - https://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database","metadata":{}},{"cell_type":"code","source":"# пути к данным\ncovid_path = '../input/covid19-radiography-database/COVID-19_Radiography_Dataset/COVID/images'\nnormal_path = '../input/covid19-radiography-database/COVID-19_Radiography_Dataset/Normal/images'\ntest_path = '../input/covid19-radiography-database/COVID-19_Radiography_Dataset/Viral Pneumonia/images'","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2022-05-07T10:54:49.861119Z","iopub.execute_input":"2022-05-07T10:54:49.861463Z","iopub.status.idle":"2022-05-07T10:54:49.865654Z","shell.execute_reply.started":"2022-05-07T10:54:49.861431Z","shell.execute_reply":"2022-05-07T10:54:49.864711Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Sorting out the files\nРазделим данные на train и valid выборки в соотношении 80:20. К распределим соответсвующие изображения по папкам.","metadata":{}},{"cell_type":"code","source":"# создания соответсвующих разделов \nos.mkdir('/kaggle/working/train')\nos.mkdir('/kaggle/working/valid')\n\nos.mkdir('/kaggle/working/train/covid')\nos.mkdir('/kaggle/working/valid/covid')\n\nos.mkdir('/kaggle/working/train/normal')\nos.mkdir('/kaggle/working/valid/normal')\n","metadata":{"execution":{"iopub.status.busy":"2022-05-07T10:54:51.250499Z","iopub.execute_input":"2022-05-07T10:54:51.250818Z","iopub.status.idle":"2022-05-07T10:54:51.256881Z","shell.execute_reply.started":"2022-05-07T10:54:51.250787Z","shell.execute_reply":"2022-05-07T10:54:51.255937Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"os.mkdir('/kaggle/working/test')","metadata":{"execution":{"iopub.status.busy":"2022-05-07T10:54:52.435218Z","iopub.execute_input":"2022-05-07T10:54:52.435698Z","iopub.status.idle":"2022-05-07T10:54:52.441626Z","shell.execute_reply.started":"2022-05-07T10:54:52.435654Z","shell.execute_reply":"2022-05-07T10:54:52.440152Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# разделение на выборки\ncovid_train_len = int(np.floor(len(os.listdir(covid_path))*0.8))\ncovid_len = len(os.listdir(covid_path))\n\nnormal_train_len = int(np.floor(len(os.listdir(normal_path))*0.8))\nnormal_len = len(os.listdir(normal_path))\ntest_len = len(os.listdir(test_path))","metadata":{"execution":{"iopub.status.busy":"2022-05-07T10:54:52.444074Z","iopub.execute_input":"2022-05-07T10:54:52.445067Z","iopub.status.idle":"2022-05-07T10:54:53.201254Z","shell.execute_reply.started":"2022-05-07T10:54:52.445018Z","shell.execute_reply":"2022-05-07T10:54:53.200182Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Переносим изображения по соответсвующим папкам\nfor trainimg in itertools.islice(glob.iglob(os.path.join(covid_path, '*.png')), covid_train_len):\n    shutil.copy(trainimg, '/kaggle/working/train/covid')\n    \nfor trainimg in itertools.islice(glob.iglob(os.path.join(normal_path, '*.png')), normal_train_len):\n    shutil.copy(trainimg, '/kaggle/working/train/normal')\n\nfor testimg in itertools.islice(glob.iglob(os.path.join(covid_path, '*.png')), covid_train_len, covid_len):\n    shutil.copy(testimg, '/kaggle/working/valid/covid')\n\nfor testimg in itertools.islice(glob.iglob(os.path.join(normal_path, '*.png')), normal_train_len, normal_len):\n    shutil.copy(testimg, '/kaggle/working/valid/normal')\n    \nfor trainimg in itertools.islice(glob.iglob(os.path.join(test_path, '*.png')), test_len):\n    shutil.copy(trainimg, '/kaggle/working/test')","metadata":{"execution":{"iopub.status.busy":"2022-05-07T10:54:53.206920Z","iopub.execute_input":"2022-05-07T10:54:53.207341Z","iopub.status.idle":"2022-05-07T10:56:23.557401Z","shell.execute_reply.started":"2022-05-07T10:54:53.207300Z","shell.execute_reply":"2022-05-07T10:56:23.556427Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class NoneTransform(object):\n    ''' Does nothing to the image. To be used instead of None '''\n    \n    def __call__(self, image):       \n        return image","metadata":{"execution":{"iopub.status.busy":"2022-05-07T10:56:23.561366Z","iopub.execute_input":"2022-05-07T10:56:23.561765Z","iopub.status.idle":"2022-05-07T10:56:23.566754Z","shell.execute_reply.started":"2022-05-07T10:56:23.561729Z","shell.execute_reply":"2022-05-07T10:56:23.565681Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class XRAY_chest(Dataset):\n    def __init__(self, files, mode):\n        super().__init__()\n        # список файлов для загрузки\n        self.files = sorted(files)\n        # режим работы\n        self.mode = mode\n\n        if self.mode not in DATA_MODES:\n            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n            raise NameError\n\n        self.len_ = len(self.files)\n     \n        self.label_encoder = LabelEncoder()\n\n        if self.mode != 'test':\n            self.labels = [path.parent.name for path in self.files]\n            self.label_encoder.fit(self.labels)\n\n            with open('label_encoder.pkl', 'wb') as le_dump_file:\n                  pickle.dump(self.label_encoder, le_dump_file)\n                      \n    def __len__(self):\n        return self.len_\n      \n    def load_sample(self, file):\n        image = Image.open(file)\n        image.load()\n        return image.convert('RGB')\n  \n    def __getitem__(self, index):\n        # для преобразования изображений в тензоры PyTorch и нормализации входа\n        x = self.load_sample(self.files[index])\n        data_transforms = {\n            'train': transforms.Compose([\n                transforms.Resize(size=(224, 224)),\n                \n                transforms.RandomHorizontalFlip(),\n                transforms.RandomRotation(degrees=30),\n                transforms.ColorJitter(hue=.1, saturation=.1),\n                transforms.ToTensor(),\n                transforms.Lambda(lambda x: x.repeat(3, 1, 1)) if x.mode!='RGB'  else NoneTransform(),\n                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n#                 transforms.Normalize((0.5), (0.5))\n            ]),\n            'val_test': transforms.Compose([\n                transforms.Resize(size=(224, 224)),\n                transforms.CenterCrop(200),\n                transforms.ToTensor(),\n                transforms.Lambda(lambda x: x.repeat(3, 1, 1)) if x.mode!='RGB'  else NoneTransform(),\n                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n#                 transforms.Normalize((0.5), (0.5))\n            ]),\n        }\n\n        transform = (data_transforms['train'] if self.mode == 'train' else \n                     data_transforms['val_test'])\n        \n        \n        x = transform(x)\n        \n        if self.mode == 'test':\n            return x\n        else:\n            label = self.labels[index]\n            label_id = self.label_encoder.transform([label])\n            y = label_id.item()\n            return x, y","metadata":{"execution":{"iopub.status.busy":"2022-05-07T10:56:23.568379Z","iopub.execute_input":"2022-05-07T10:56:23.569081Z","iopub.status.idle":"2022-05-07T10:56:23.590968Z","shell.execute_reply.started":"2022-05-07T10:56:23.569039Z","shell.execute_reply":"2022-05-07T10:56:23.590173Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def imshow(inp, title=None, plt_ax=plt, default=False):\n    \"\"\"Imshow для тензоров\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt_ax.imshow(inp)\n    if title is not None:\n        plt_ax.set_title(title)\n    plt_ax.grid(False)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T10:56:23.592233Z","iopub.execute_input":"2022-05-07T10:56:23.592511Z","iopub.status.idle":"2022-05-07T10:56:23.604064Z","shell.execute_reply.started":"2022-05-07T10:56:23.592484Z","shell.execute_reply":"2022-05-07T10:56:23.603386Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"DATA_MODES = ['train', 'val', 'test']","metadata":{"execution":{"iopub.status.busy":"2022-05-07T10:56:23.607678Z","iopub.execute_input":"2022-05-07T10:56:23.608088Z","iopub.status.idle":"2022-05-07T10:56:23.613212Z","shell.execute_reply.started":"2022-05-07T10:56:23.608047Z","shell.execute_reply":"2022-05-07T10:56:23.612183Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#список файлов в каждой категории\nTRAIN_DIR = Path('/kaggle/working/train')\nVAL_DIR = Path('/kaggle/working/valid')\nTEST_DIR = Path('/kaggle/working/test')\n\ntrain_files = sorted(list(TRAIN_DIR.rglob('*.png')))\nval_files = sorted(list(VAL_DIR.rglob('*.png')))\ntest_files = sorted(list(TEST_DIR.rglob('*.png')))","metadata":{"execution":{"iopub.status.busy":"2022-05-07T10:56:23.615343Z","iopub.execute_input":"2022-05-07T10:56:23.615734Z","iopub.status.idle":"2022-05-07T10:56:23.844656Z","shell.execute_reply.started":"2022-05-07T10:56:23.615695Z","shell.execute_reply":"2022-05-07T10:56:23.843792Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# выведем пример\nval_dataset = XRAY_chest(val_files, mode='val')\n\nfig, ax = plt.subplots(nrows=3, ncols=3,figsize=(8, 8), \\\n                        sharey=True, sharex=True)\nfor fig_x in ax.flatten():\n    random_characters = int(np.random.uniform(0,1000))\n    im_val, label = val_dataset[random_characters]\n    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n    imshow(im_val.data.cpu(), \\\n          title=img_label,plt_ax=fig_x)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T10:56:23.846787Z","iopub.execute_input":"2022-05-07T10:56:23.847326Z","iopub.status.idle":"2022-05-07T10:56:25.400325Z","shell.execute_reply.started":"2022-05-07T10:56:23.847282Z","shell.execute_reply":"2022-05-07T10:56:25.399371Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Преобразуем данные","metadata":{}},{"cell_type":"code","source":"if val_dataset is None:\n    val_dataset = XRAY_chest(val_files, mode='val')\n    \ntrain_dataset = XRAY_chest(train_files, mode='train')","metadata":{"execution":{"iopub.status.busy":"2022-05-07T10:56:25.401467Z","iopub.execute_input":"2022-05-07T10:56:25.401785Z","iopub.status.idle":"2022-05-07T10:56:25.445081Z","shell.execute_reply.started":"2022-05-07T10:56:25.401754Z","shell.execute_reply":"2022-05-07T10:56:25.444270Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Creating model","metadata":{}},{"cell_type":"code","source":"# проверяем возможность учится на gpu\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-05-07T10:56:25.446501Z","iopub.execute_input":"2022-05-07T10:56:25.446987Z","iopub.status.idle":"2022-05-07T10:56:25.521418Z","shell.execute_reply.started":"2022-05-07T10:56:25.446947Z","shell.execute_reply":"2022-05-07T10:56:25.520398Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def fit_epoch(model, train_loader, criterion, optimizer):\n    running_loss = 0.0\n    running_corrects = 0\n    processed_data = 0\n  \n    for inputs, labels in train_loader:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        optimizer.zero_grad()\n\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n\n        optimizer.step()\n\n        preds = torch.argmax(outputs, 1)\n        \n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n        processed_data += inputs.size(0)\n              \n    train_loss = running_loss / processed_data\n    train_acc = running_corrects.cpu().numpy() / processed_data\n    return train_loss, train_acc","metadata":{"execution":{"iopub.status.busy":"2022-05-07T10:56:25.523224Z","iopub.execute_input":"2022-05-07T10:56:25.523685Z","iopub.status.idle":"2022-05-07T10:56:25.626884Z","shell.execute_reply.started":"2022-05-07T10:56:25.523648Z","shell.execute_reply":"2022-05-07T10:56:25.625867Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def eval_epoch(model, val_loader, criterion):\n    model.eval()\n\n    running_loss = 0.0\n    running_corrects = 0\n    processed_size = 0\n\n    for inputs, labels in val_loader:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        with torch.set_grad_enabled(False):\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            preds = torch.argmax(outputs, 1)\n\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n        processed_size += inputs.size(0)\n        \n    val_loss = running_loss / processed_size\n    val_acc = running_corrects.double() / processed_size\n    return val_loss, val_acc","metadata":{"execution":{"iopub.status.busy":"2022-05-07T10:56:25.628555Z","iopub.execute_input":"2022-05-07T10:56:25.628992Z","iopub.status.idle":"2022-05-07T10:56:25.642001Z","shell.execute_reply.started":"2022-05-07T10:56:25.628948Z","shell.execute_reply":"2022-05-07T10:56:25.641182Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def train(train_files, val_files, model, optimizer, \n          criterion, epochs, batch_size,scheduler):\n  \n    train_loader = DataLoader(train_dataset, batch_size=batch_size, \n                              shuffle=True, num_workers=4)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, \n                            shuffle=False, num_workers=4)\n\n    history = []\n    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}\"\n\n    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n        \n        for epoch in range(epochs):\n            train_loss, train_acc = fit_epoch(model, train_loader, \n                                              criterion, optimizer)\n            print(\"loss\", train_loss)\n            \n            val_loss, val_acc = eval_epoch(model, val_loader, criterion)\n            print(\"val loss:\", val_loss)\n\n            history.append((train_loss, train_acc, val_loss, val_acc))\n\n            scheduler.step()\n            \n            pbar_outer.update(1)\n            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\\\n                                           v_loss=val_loss, t_acc=train_acc, \n                                           v_acc=val_acc))\n            \n    return history","metadata":{"execution":{"iopub.status.busy":"2022-05-07T10:57:08.646468Z","iopub.execute_input":"2022-05-07T10:57:08.646813Z","iopub.status.idle":"2022-05-07T10:57:08.657776Z","shell.execute_reply.started":"2022-05-07T10:57:08.646776Z","shell.execute_reply":"2022-05-07T10:57:08.656803Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def predict(model, test_loader):\n    with torch.no_grad():\n        logits = []\n    \n        for inputs in test_loader:\n            inputs = inputs.to(device)\n            model.eval()\n            outputs = model(inputs).cpu()\n            logits.append(outputs)\n            \n    probs = nn.functional.softmax(torch.cat(logits), dim=-1).numpy()\n    return probs","metadata":{"execution":{"iopub.status.busy":"2022-05-07T10:56:25.662594Z","iopub.execute_input":"2022-05-07T10:56:25.663010Z","iopub.status.idle":"2022-05-07T10:56:25.671958Z","shell.execute_reply.started":"2022-05-07T10:56:25.662970Z","shell.execute_reply":"2022-05-07T10:56:25.670923Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# Prepare model","metadata":{}},{"cell_type":"code","source":"resnet = models.resnet18(pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T10:56:25.673459Z","iopub.execute_input":"2022-05-07T10:56:25.674074Z","iopub.status.idle":"2022-05-07T10:56:26.758533Z","shell.execute_reply.started":"2022-05-07T10:56:25.674031Z","shell.execute_reply":"2022-05-07T10:56:26.757624Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# замораживаем параметры (веса)\nfor param in resnet.parameters():\n    param.requires_grad = True\n\n# num_features -- это размерность вектора фич, поступающего на вход FC-слою\nnum_features = resnet.fc.in_features\nn_classes = 2\n# Заменяем Fully-Connected слой на наш линейный классификатор\nresnet.fc = nn.Linear(num_features, n_classes)\nresnet = resnet.to(device)\n\n# Определяем оптимизатор, критерий\noptimizer = optim.AdamW(resnet.parameters(),lr=1e-4)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, 3, 0.5)\n\ncriterion=nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T10:56:26.760393Z","iopub.execute_input":"2022-05-07T10:56:26.760763Z","iopub.status.idle":"2022-05-07T10:56:30.354663Z","shell.execute_reply.started":"2022-05-07T10:56:26.760724Z","shell.execute_reply":"2022-05-07T10:56:30.353789Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Learn model","metadata":{}},{"cell_type":"code","source":"# запускаем обучение\nresnet_fine = train(train_dataset, val_dataset, model=resnet, criterion=criterion,\n                          epochs=10, batch_size=16, optimizer=optimizer, scheduler=scheduler)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T10:57:13.442582Z","iopub.execute_input":"2022-05-07T10:57:13.443231Z","iopub.status.idle":"2022-05-07T11:09:52.365779Z","shell.execute_reply.started":"2022-05-07T10:57:13.443186Z","shell.execute_reply":"2022-05-07T11:09:52.364824Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"loss, acc, val_loss, val_acc = zip(*resnet_fine)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T11:10:19.143726Z","iopub.execute_input":"2022-05-07T11:10:19.144113Z","iopub.status.idle":"2022-05-07T11:10:19.149531Z","shell.execute_reply.started":"2022-05-07T11:10:19.144078Z","shell.execute_reply":"2022-05-07T11:10:19.148310Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 9))\nplt.plot(loss, label=\"train_loss\")\nplt.plot(val_loss, label=\"val_loss\")\nplt.legend(loc='best')\nplt.xlabel(\"epochs\")\nplt.ylabel(\"loss\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T11:10:20.148645Z","iopub.execute_input":"2022-05-07T11:10:20.148987Z","iopub.status.idle":"2022-05-07T11:10:20.319781Z","shell.execute_reply.started":"2022-05-07T11:10:20.148954Z","shell.execute_reply":"2022-05-07T11:10:20.318781Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"#dir for save model\nos.mkdir('/kaggle/working/models')","metadata":{"execution":{"iopub.status.busy":"2022-05-07T11:10:22.722026Z","iopub.execute_input":"2022-05-07T11:10:22.724759Z","iopub.status.idle":"2022-05-07T11:10:22.731200Z","shell.execute_reply.started":"2022-05-07T11:10:22.724708Z","shell.execute_reply":"2022-05-07T11:10:22.729940Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"#save model\ntorch.save(resnet.state_dict(), 'models/weights.h5') #save the model's weights\n#load model\n# model.load_state_dict(torch.load('models/weights.h5')) #load the model's weights","metadata":{"execution":{"iopub.status.busy":"2022-05-07T11:10:23.655730Z","iopub.execute_input":"2022-05-07T11:10:23.656138Z","iopub.status.idle":"2022-05-07T11:10:23.773714Z","shell.execute_reply.started":"2022-05-07T11:10:23.656103Z","shell.execute_reply":"2022-05-07T11:10:23.772818Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"# Vusialization results","metadata":{}},{"cell_type":"code","source":"def predict_one_sample(model, inputs, device=device):\n    \"\"\"Предсказание, для одной картинки\"\"\"\n    with torch.no_grad():\n        inputs = inputs.to(device)\n        model.eval()\n        logit = model(inputs).cpu()\n        probs = torch.nn.functional.softmax(logit, dim=-1).numpy()\n    return probs","metadata":{"execution":{"iopub.status.busy":"2022-05-07T11:10:26.332254Z","iopub.execute_input":"2022-05-07T11:10:26.332591Z","iopub.status.idle":"2022-05-07T11:10:26.338794Z","shell.execute_reply.started":"2022-05-07T11:10:26.332560Z","shell.execute_reply":"2022-05-07T11:10:26.337895Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))","metadata":{"execution":{"iopub.status.busy":"2022-05-07T11:12:40.285578Z","iopub.execute_input":"2022-05-07T11:12:40.285969Z","iopub.status.idle":"2022-05-07T11:12:40.293011Z","shell.execute_reply.started":"2022-05-07T11:12:40.285930Z","shell.execute_reply":"2022-05-07T11:12:40.291998Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# небольшая визуализация\n\nfig, ax = plt.subplots(nrows=3, ncols=3,figsize=(12, 12), \\\n                        sharey=True, sharex=True)\nfor fig_x in ax.flatten():\n    random_characters = int(np.random.uniform(0,1000))\n    im_val, label = val_dataset[random_characters]\n    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n    \n    \n\n    imshow(im_val.data.cpu(), \\\n          title=img_label,plt_ax=fig_x)\n    \n    actual_text = \"Actual : {}\".format(img_label)\n            \n    fig_x.add_patch(patches.Rectangle((0, 200),120,30,color='white'))\n    font0 = FontProperties()\n    font = font0.copy()\n    font.set_family(\"fantasy\")\n    prob_pred = predict_one_sample(resnet, im_val.unsqueeze(0))\n    predicted_proba = np.max(prob_pred)*100\n    y_pred = np.argmax(prob_pred)\n    \n    predicted_label = label_encoder.classes_[y_pred]\n    predicted_text = \"{} : {:.0f}%\".format(predicted_label,predicted_proba)\n            \n    fig_x.text(100, 200, predicted_text , horizontalalignment='center', fontproperties=font,\n                    verticalalignment='top',fontsize=10, color='black',fontweight='bold')","metadata":{"execution":{"iopub.status.busy":"2022-05-07T11:12:40.296735Z","iopub.execute_input":"2022-05-07T11:12:40.298382Z","iopub.status.idle":"2022-05-07T11:12:42.269272Z","shell.execute_reply.started":"2022-05-07T11:12:40.298332Z","shell.execute_reply":"2022-05-07T11:12:42.267973Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"# F1 по valid dataset","metadata":{}},{"cell_type":"code","source":"# прогоняем сеть по всему val_dataset \n\nimgs = [val_dataset[id][0].unsqueeze(0) for id in range(len(val_dataset))]\n\nprobs_ims = predict(resnet, imgs)\n\ny_pred = np.argmax(probs_ims,-1)\nactual_labels = [val_dataset[id][1] for id in range(len(val_dataset))]\npreds_class = [label_encoder.classes_[i] for i in y_pred]\nactual_class = [label_encoder.classes_[i] for i in actual_labels]","metadata":{"execution":{"iopub.status.busy":"2022-05-07T11:12:06.051627Z","iopub.execute_input":"2022-05-07T11:12:06.051978Z","iopub.status.idle":"2022-05-07T11:12:38.506536Z","shell.execute_reply.started":"2022-05-07T11:12:06.051947Z","shell.execute_reply":"2022-05-07T11:12:38.505729Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"print(classification_report(actual_class, preds_class))","metadata":{"execution":{"iopub.status.busy":"2022-05-07T11:12:38.508719Z","iopub.execute_input":"2022-05-07T11:12:38.509114Z","iopub.status.idle":"2022-05-07T11:12:38.543519Z","shell.execute_reply.started":"2022-05-07T11:12:38.509076Z","shell.execute_reply":"2022-05-07T11:12:38.542720Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# Make prediction for unknown data covid or normal\n\n Я сделал на valid выборке, можно потестить на другом датасете","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model, test_loader):\n    with torch.no_grad():\n        logits = []\n    \n        for inputs in test_loader:\n            inputs = inputs.to(device)\n            model.eval()\n            outputs = model(inputs).cpu()\n            logits.append(outputs)\n            \n    probs = nn.functional.softmax(torch.cat(logits), dim=-1).numpy()\n    return probs","metadata":{"execution":{"iopub.status.busy":"2022-05-07T11:12:49.152637Z","iopub.execute_input":"2022-05-07T11:12:49.152982Z","iopub.status.idle":"2022-05-07T11:12:49.159691Z","shell.execute_reply.started":"2022-05-07T11:12:49.152950Z","shell.execute_reply":"2022-05-07T11:12:49.158822Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"test_dataset = XRAY_chest(test_files, mode=\"test\")\ntest_loader = DataLoader(test_dataset, shuffle=False, batch_size=64)\nprobs = predict(resnet, test_loader)\nlabel_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))\n\npreds = label_encoder.inverse_transform(np.argmax(probs, axis=1))","metadata":{"execution":{"iopub.status.busy":"2022-05-07T11:12:49.982180Z","iopub.execute_input":"2022-05-07T11:12:49.982605Z","iopub.status.idle":"2022-05-07T11:12:56.534647Z","shell.execute_reply.started":"2022-05-07T11:12:49.982557Z","shell.execute_reply":"2022-05-07T11:12:56.533867Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"unique, counts = np.unique(preds, return_counts=True)\ndict(zip(unique, counts))","metadata":{"execution":{"iopub.status.busy":"2022-05-07T11:12:56.536318Z","iopub.execute_input":"2022-05-07T11:12:56.536700Z","iopub.status.idle":"2022-05-07T11:12:56.543383Z","shell.execute_reply.started":"2022-05-07T11:12:56.536625Z","shell.execute_reply":"2022-05-07T11:12:56.542347Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Альтернативная модель","metadata":{}},{"cell_type":"code","source":"model = models.densenet121(pretrained=True)\n# замораживаем параметры (веса)\nfor param in model.parameters():\n    param.requires_grad = False\n# num_features -- это размерность вектора фич, поступающего на вход FC-слою\n\n# num_features = model.fc.in_features\nn_classes = 2\n# Заменяем Fully-Connected слой на наш линейный классификатор\nmodel.classifier = nn.Linear(1024, n_classes)\nmodel = model.to(device)\n\n# Определяем оптимизатор, критерий\ncriterion = nn.CrossEntropyLoss()\n# optimizer = optim.AdamW(model.classifier.parameters())\noptimizer = optim.SGD(model.classifier.parameters(),lr=0.1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#запускаем\nresult_model_2 = trained_model(model=model, dataloaders=dataloaders, criterion=criterion, optimizer=optimizer, epochs=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss(history_2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_list, y_true_list = predict(result_model_2, dataloaders['validation'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_true_list, y_pred_list))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}